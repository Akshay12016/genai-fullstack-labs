{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb700b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator(expr: str):\n",
    "    return eval(expr)\n",
    "\n",
    "def order_status(order_id: int):\n",
    "    return f\"Order {order_id} is shipped\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea54fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    reasoning: str\n",
    "    action: str\n",
    "    observation: str\n",
    "    output: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5d8e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apoliset\\AppData\\Local\\Temp\\ipykernel_30876\\3381925528.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "def reasoning_node(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "You are a ReAct agent.\n",
    "\n",
    "User query: {state['input']}\n",
    "\n",
    "Decide:\n",
    "- reasoning\n",
    "- action (calculator / order_status / none)\n",
    "Return in this format:\n",
    "REASONING:\n",
    "ACTION:\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    text = response.content\n",
    "\n",
    "    reasoning, action = text.split(\"ACTION:\")\n",
    "    return {\n",
    "        \"reasoning\": reasoning.replace(\"REASONING:\", \"\").strip(),\n",
    "        \"action\": action.strip()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7325e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_node(state: AgentState):\n",
    "    action = state[\"action\"]\n",
    "\n",
    "    if action.startswith(\"calculator\"):\n",
    "        expr = action.replace(\"calculator\", \"\").strip()\n",
    "        return {\"observation\": str(calculator(expr))}\n",
    "\n",
    "    if action.startswith(\"order_status\"):\n",
    "        order_id = int(action.replace(\"order_status\", \"\").strip())\n",
    "        return {\"observation\": order_status(order_id)}\n",
    "\n",
    "    return {\"observation\": \"No action taken\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5649d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_node(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "User question: {state['input']}\n",
    "Reasoning: {state['reasoning']}\n",
    "Observation: {state['observation']}\n",
    "\n",
    "Provide final answer.\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"output\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5e60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"reasoning\", reasoning_node)\n",
    "graph.add_node(\"action\", action_node)\n",
    "graph.add_node(\"final\", final_node)\n",
    "\n",
    "graph.set_entry_point(\"reasoning\")\n",
    "graph.add_edge(\"reasoning\", \"action\")\n",
    "graph.add_edge(\"action\", \"final\")\n",
    "\n",
    "react_agent = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15797870",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3701\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[8]\u001b[39m\u001b[92m, line 1\u001b[39m\n    react_agent.invoke({\n",
      "  File \u001b[92mc:\\Users\\apoliset\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m in \u001b[95minvoke\u001b[39m\n    for chunk in self.stream(\n",
      "  File \u001b[92mc:\\Users\\apoliset\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m in \u001b[95mstream\u001b[39m\n    for _ in runner.tick(\n",
      "  File \u001b[92mc:\\Users\\apoliset\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m in \u001b[95mtick\u001b[39m\n    run_with_retry(\n",
      "  File \u001b[92mc:\\Users\\apoliset\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m in \u001b[95mrun_with_retry\u001b[39m\n    return task.proc.invoke(task.input, config)\n",
      "  File \u001b[92mc:\\Users\\apoliset\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m in \u001b[95minvoke\u001b[39m\n    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \u001b[92mc:\\Users\\apoliset\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m in \u001b[95minvoke\u001b[39m\n    ret = self.func(*args, **kwargs)\n",
      "  Cell \u001b[92mIn[5]\u001b[39m\u001b[92m, line 6\u001b[39m in \u001b[95maction_node\u001b[39m\n    return {\"observation\": str(calculator(expr))}\n",
      "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\u001b[36m in \u001b[39m\u001b[35mcalculator\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn eval(expr)\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m: To perform the arithmetic operation 20 * 5, I will use my built-in  functionality.\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\nDuring task with name 'action' and id 'd2d6d32c-9705-9f97-5797-96817428671a'\n"
     ]
    }
   ],
   "source": [
    "react_agent.invoke({\n",
    "    \"input\": \"What is 20 * 5 and check order status for order 101\"\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
