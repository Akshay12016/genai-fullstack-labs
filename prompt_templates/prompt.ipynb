{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4343c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apoliset\\AppData\\Local\\Temp\\ipykernel_16284\\3343363915.py:5: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Vector databases are a type of database that stores and manages data in the form of vectors, which are mathematical concepts used to represent complex patterns or relationships between objects.\\n\\nIn simple terms, think of a vector as an arrow in space that has both length (magnitude) and direction. Each point in space can be represented by its position coordinates (x, y, z). In the same way, each object or concept in your data can be represented by a set of features (e.g., words, numbers, images) that are used to define its properties.\\n\\nHere\\'s how vector databases work:\\n\\n1. **Data Representation**: Each record or entity in your database is converted into a mathematical vector representation. For example:\\n\\t* A text document becomes a vector where each dimension corresponds to the frequency of a specific word.\\n\\t* An image becomes a vector where each dimension corresponds to the intensity of a specific pixel color.\\n2. **Similarity Search**: Vector databases use algorithms that can find similar vectors in the database. This is useful when you want to search for objects that are close or identical, but not necessarily exact matches.\\n3. **Indexing and Querying**: The database maintains an index on these vector representations, allowing for fast querying of similar data points. You can ask questions like: \"Find all documents that are 80% similar to this one\" or \"Return all images that have a similar color profile.\"\\n4. **Operations and Analysis**: Vector databases support various operations, such as:\\n\\t* Distance calculation (e.g., Euclidean distance) to measure similarity between vectors.\\n\\t* Dimensionality reduction techniques (e.g., PCA, t-SNE) to reduce the number of features and improve query performance.\\n\\nVector databases are particularly useful for:\\n\\n1. **Text search**: Search for similar documents or texts based on their word frequencies.\\n2. **Image retrieval**: Find images that are visually similar to a given image.\\n3. **Recommendation systems**: Suggest items (e.g., products, movies) that are similar to ones the user has interacted with before.\\n\\nSome popular vector databases include:\\n\\n1. Apache Pinot\\n2. RedisGraph\\n3. Amazon SageMaker\\n4. OpenCV\\n\\nKeep in mind that vector databases require a solid understanding of mathematical concepts and algorithms, as well as large amounts of computational resources. However, they can be incredibly powerful tools for analyzing complex data sets and finding meaningful relationships between objects.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in simple terms.\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"topic\": \"Vector Databases\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05841ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Input Variables and role prompting\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"role\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a {role}.\n",
    "Answer the following question clearly:\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"role\": \"Senior Backend Engineer\",\n",
    "    \"question\": \"What is FastAPI?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5620f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#few shot prompting\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "Q: What is Python?\n",
    "A: Python is a programming language.\n",
    "\n",
    "Q: What is FastAPI?\n",
    "A: FastAPI is a Python web framework.\n",
    "\n",
    "Q: {question}\n",
    "A:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt + RunnablePassthrough\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough()\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Explain RAG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
